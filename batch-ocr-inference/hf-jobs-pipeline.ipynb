{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek OCR Job Pipeline\n",
    "\n",
    "This notebook runs a three-stage OCR pipeline on Hugging Face Jobs:\n",
    "\n",
    "1. **Extract** – Run DeepSeek OCR over a dataset, save Markdown and crop detected figures\n",
    "2. **Describe** – Generate captions for extracted figures  \n",
    "3. **Assemble** – Enrich Markdown with figure captions\n",
    "\n",
    "All stages share a single HF dataset repository. Each stage loads the dataset, processes it, and pushes updates back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo, fetch_job_logs, inspect_job, run_uv_job, whoami\n",
    "from huggingface_hub._jobs_api import JobInfo, JobStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: florentgbelidji/deepseek-ocr-job-code | Dataset: florentgbelidji/deepseek-ocr-dataset\n",
      "Source: HuggingFaceM4/FineVision/olmOCR-mix-0225-documents (50 samples)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "USERNAME = whoami()[\"name\"]\n",
    "\n",
    "HUB_IMAGE = \"vllm/vllm-openai:v0.12.0\"\n",
    "HARDWARE = \"a100-large\"\n",
    "TIMEOUT = \"3h\"\n",
    "\n",
    "CODE_REPO = f\"{USERNAME}/deepseek-ocr-job-code\"\n",
    "DATASET_REPO = f\"{USERNAME}/deepseek-ocr-dataset\"\n",
    "\n",
    "# Source dataset\n",
    "SOURCE_DATASET = \"HuggingFaceM4/FineVision\"\n",
    "SOURCE_CONFIG = \"olmOCR-mix-0225-documents\"\n",
    "MAX_SAMPLES = 50\n",
    "\n",
    "print(f\"Code: {CODE_REPO} | Dataset: {DATASET_REPO}\")\n",
    "print(f\"Source: {SOURCE_DATASET}/{SOURCE_CONFIG} ({MAX_SAMPLES} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base environment for all stages\n",
    "BASE_ENV = {\n",
    "    # vLLM\n",
    "    \"MODEL_ID\": \"deepseek-ai/DeepSeek-OCR\",\n",
    "    \"SERVED_MODEL_NAME\": \"deepseek-ocr\",\n",
    "    \"HOST\": \"0.0.0.0\",\n",
    "    \"PORT\": \"8000\",\n",
    "    \"MAX_MODEL_LEN\": \"8192\",\n",
    "    \"GPU_MEMORY_UTILIZATION\": \"0.90\",\n",
    "    \"TENSOR_PARALLEL_SIZE\": \"1\",\n",
    "    # Code\n",
    "    \"JOB_CODE_REPO\": CODE_REPO,\n",
    "    \"JOB_CODE_REVISION\": \"main\",\n",
    "    \"JOB_CODE_LOCAL_DIR\": \"/tmp/deepseek-ocr-job-code\",\n",
    "    # Auth\n",
    "    \"HF_TOKEN\": os.environ.get(\"HF_TOKEN\", \"\"),\n",
    "    # Prompts\n",
    "    \"DOC_PROMPT\": \"<image>\\n<|grounding|>Convert this document to Markdown.\",\n",
    "    \"DOC_MAX_TOKENS\": \"4096\",\n",
    "    \"DOC_TEMPERATURE\": \"0.1\",\n",
    "    \"FIGURE_PROMPT\": \"<image>\\nDescribe this image in detail.\",\n",
    "    \"FIGURE_MAX_TOKENS\": \"512\",\n",
    "    \"FIGURE_TEMPERATURE\": \"0.6\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded code to florentgbelidji/deepseek-ocr-job-code\n"
     ]
    }
   ],
   "source": [
    "# Upload code to HF Hub\n",
    "CODE_PATHS = [\n",
    "    Path(\"ds-batch-ocr.py\"),\n",
    "    Path(\"hf_job_runner.py\"),\n",
    "    Path(\"ds_batch_ocr\"),\n",
    "]\n",
    "\n",
    "api = HfApi()\n",
    "create_repo(repo_id=CODE_REPO, repo_type=\"dataset\", exist_ok=True)\n",
    "create_repo(repo_id=DATASET_REPO, repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "bundle_dir = Path(tempfile.mkdtemp(prefix=\"job-code-\"))\n",
    "for path in CODE_PATHS:\n",
    "    src = Path.cwd() / path if not path.is_absolute() else path\n",
    "    if src.is_dir():\n",
    "        shutil.copytree(src, bundle_dir / path.name, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(src, bundle_dir / path.name)\n",
    "\n",
    "api.upload_folder(folder_path=str(bundle_dir), repo_id=CODE_REPO, repo_type=\"dataset\")\n",
    "print(f\"Uploaded code to {CODE_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "CODE_URL = f\"https://huggingface.co/datasets/{CODE_REPO}/resolve/main/hf_job_runner.py\"\n",
    "\n",
    "def launch(stage: str, flavor: str, env: dict) -> JobInfo:\n",
    "    full_env = {**BASE_ENV, **env, \"PIPELINE_STAGE\": stage}\n",
    "    job = run_uv_job(CODE_URL, image=HUB_IMAGE, flavor=flavor, env=full_env, timeout=TIMEOUT)\n",
    "    print(f\"Launched {stage}: {job.url}\")\n",
    "    return job\n",
    "\n",
    "def wait(job: JobInfo, poll: int = 60) -> JobInfo:\n",
    "    while True:\n",
    "        info = inspect_job(job_id=job.id)\n",
    "        stage = info.status.stage\n",
    "        print(f\"  {job.id}: {stage}\")\n",
    "        if stage not in {JobStage.RUNNING, \"RUNNING\", \"UPDATING\"}:\n",
    "            return info\n",
    "        time.sleep(poll)\n",
    "\n",
    "def logs(job: JobInfo, tail: int = 100):\n",
    "    for line in list(fetch_job_logs(job_id=job.id, namespace=job.owner.name))[-tail:]:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched extract: https://huggingface.co/jobs/florentgbelidji/693ac3ce1a39f67af5a41bdb\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: Extract\n",
    "stage1 = launch(\"extract\", flavor=HARDWARE, env={\n",
    "    \"DATASET_NAME\": SOURCE_DATASET,\n",
    "    \"DATASET_CONFIG\": SOURCE_CONFIG,\n",
    "    \"DATASET_SPLIT\": \"train\",\n",
    "    \"MAX_SAMPLES\": str(MAX_SAMPLES),\n",
    "    \"OUTPUT_DIR\": \"./outputs/extract\",\n",
    "    \"EXTRACT_BATCH_SIZE\": \"256\",\n",
    "    \"EXTRACT_MAX_CONCURRENCY\": \"8\",\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_PATH_IN_REPO\": \"outputs/extract\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  693ac3ce1a39f67af5a41bdb: RUNNING\n",
      "  693ac3ce1a39f67af5a41bdb: RUNNING\n",
      "  693ac3ce1a39f67af5a41bdb: RUNNING\n",
      "  693ac3ce1a39f67af5a41bdb: RUNNING\n",
      "  693ac3ce1a39f67af5a41bdb: COMPLETED\n",
      "Extract complete: florentgbelidji/deepseek-ocr-dataset\n"
     ]
    }
   ],
   "source": [
    "stage1_done = wait(stage1)\n",
    "print(f\"Extract complete: {DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.18s/ shards]2025-12-11 05:21:12,618 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset \"HTTP/1.1 200 OK\"2025-12-11 05:21:12,645 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/tree/697fc73bb6ae6f6f7c7a9d061ebb7d1b7e83e90d?recursive=true&expand=false \"HTTP/1.1 200 OK\"2025-12-11 05:21:12,657 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/validate-yaml \"HTTP/1.1 200 OK\"2025-12-11 05:21:12,807 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/preupload/main \"HTTP/1.1 200 OK\"2025-12-11 05:21:13,114 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/commit/main \"HTTP/1.1 200 OK\"2025-12-11 05:21:13,114 | INFO | ds_batch_ocr.stages | Extract complete | docs=50 | failures=02025-12-11 05:21:13,211 | INFO | ds_batch_ocr.server | Shutting down vLLM server[vLLM STDOUT] \u001b[0;36m(APIServer pid=133)\u001b[0;0m INFO 12-11 05:21:13 [launcher.py:110] Shutting down FastAPI HTTP server.[vLLM STDERR] [rank0]:[W1211 05:21:13.711499005 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())[vLLM STDERR] \u001b[0;36m(APIServer pid=133)\u001b[0;0m INFO:     Shutting down[vLLM STDOUT] \u001b[0;36m(APIServer pid=133)\u001b[0;0m INFO 12-11 05:21:14 [loggers.py:236] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%[vLLM STDERR] \u001b[0;36m(APIServer pid=133)\u001b[0;0m INFO:     Waiting for application shutdown.[vLLM STDERR] \u001b[0;36m(APIServer pid=133)\u001b[0;0m INFO:     Application shutdown complete."
     ]
    }
   ],
   "source": [
    "logs(stage1_done, tail=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched describe: https://huggingface.co/jobs/florentgbelidji/693ac5871a39f67af5a41be0\n"
     ]
    }
   ],
   "source": [
    "# Stage 2: Describe\n",
    "stage2 = launch(\"describe\", flavor=HARDWARE, env={\n",
    "    \"OUTPUT_DIR\": \"./outputs/describe\",\n",
    "    \"DESCRIBE_BATCH_SIZE\": \"8\",\n",
    "    \"DESCRIBE_MAX_CONCURRENCY\": \"4\",\n",
    "    \"SOURCE_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  693ac5871a39f67af5a41be0: RUNNING\n",
      "  693ac5871a39f67af5a41be0: RUNNING\n",
      "  693ac5871a39f67af5a41be0: RUNNING\n",
      "  693ac5871a39f67af5a41be0: RUNNING\n",
      "  693ac5871a39f67af5a41be0: COMPLETED\n",
      "Describe complete: florentgbelidji/deepseek-ocr-dataset\n"
     ]
    }
   ],
   "source": [
    "stage2_done = wait(stage2)\n",
    "print(f\"Describe complete: {DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.64s/ shards]2025-12-11 05:25:18,794 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset \"HTTP/1.1 200 OK\"2025-12-11 05:25:18,827 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/tree/89c9ba857956613e57619b5d1c5b99d18af6abc1?recursive=true&expand=false \"HTTP/1.1 200 OK\"2025-12-11 05:25:18,837 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/validate-yaml \"HTTP/1.1 200 OK\"2025-12-11 05:25:18,897 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/preupload/main \"HTTP/1.1 200 OK\"2025-12-11 05:25:19,305 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/commit/main \"HTTP/1.1 200 OK\"2025-12-11 05:25:19,306 | INFO | ds_batch_ocr.stages | Describe complete | described=16 | failures=12025-12-11 05:25:19,307 | INFO | ds_batch_ocr.server | Shutting down vLLM server[vLLM STDOUT] \u001b[0;36m(APIServer pid=137)\u001b[0;0m INFO 12-11 05:25:19 [launcher.py:110] Shutting down FastAPI HTTP server.[vLLM STDERR] [rank0]:[W1211 05:25:19.779571812 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())[vLLM STDERR] \u001b[0;36m(APIServer pid=137)\u001b[0;0m INFO:     Shutting down[vLLM STDERR] \u001b[0;36m(APIServer pid=137)\u001b[0;0m INFO:     Waiting for application shutdown.[vLLM STDERR] \u001b[0;36m(APIServer pid=137)\u001b[0;0m INFO:     Application shutdown complete."
     ]
    }
   ],
   "source": [
    "logs(stage2_done, tail=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched assemble: https://huggingface.co/jobs/florentgbelidji/693ac781c67c9f186cfe22bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/lib/python3.12/site-packages/huggingface_hub/utils/_experimental.py:60: UserWarning: 'HfApi.run_uv_job' is experimental and might be subject to breaking changes in the future without prior notice. You can disable this warning by setting `HF_HUB_DISABLE_EXPERIMENTAL_WARNING=1` as environment variable.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Stage 3: Assemble\n",
    "stage3 = launch(\"assemble\", flavor='cpu-upgrade', env={\n",
    "    \"SOURCE_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_COMMIT_MESSAGE\": \"Add assembled documents with figure captions\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  693ac781c67c9f186cfe22bc: RUNNING\n",
      "  693ac781c67c9f186cfe22bc: RUNNING\n",
      "  693ac781c67c9f186cfe22bc: RUNNING\n",
      "  693ac781c67c9f186cfe22bc: RUNNING\n",
      "  693ac781c67c9f186cfe22bc: COMPLETED\n",
      "Pipeline complete! Dataset: https://huggingface.co/datasets/florentgbelidji/deepseek-ocr-dataset\n"
     ]
    }
   ],
   "source": [
    "stage3_done = wait(stage3)\n",
    "print(f\"Pipeline complete! Dataset: https://huggingface.co/datasets/{DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.52s/ shards]2025-12-11 05:34:08,844 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset \"HTTP/1.1 200 OK\"2025-12-11 05:34:08,999 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/tree/7c711a21ad466896107bdd1732321a2192b1291b?recursive=true&expand=false \"HTTP/1.1 200 OK\"2025-12-11 05:34:09,011 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/validate-yaml \"HTTP/1.1 200 OK\"2025-12-11 05:34:09,247 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/preupload/main \"HTTP/1.1 200 OK\"2025-12-11 05:34:11,010 | INFO | httpx | HTTP Request: POST https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/commit/main \"HTTP/1.1 200 OK\"2025-12-11 05:34:11,010 | INFO | ds_batch_ocr.stages | Assemble complete/deepseek-ocr-dataset.py \"HTTP/1.1 404 Not Found\"2025-12-11 05:34:05,357 | INFO | httpx | HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/florentgbelidji/deepseek-ocr-dataset/florentgbelidji/deepseek-ocr-dataset.py \"HTTP/1.1 404 Not Found\"2025-12-11 05:34:05,383 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/revision/7c711a21ad466896107bdd1732321a2192b1291b \"HTTP/1.1 200 OK\"2025-12-11 05:34:05,712 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/florentgbelidji/deepseek-ocr-dataset/resolve/7c711a21ad466896107bdd1732321a2192b1291b/.huggingface.yaml \"HTTP/1.1 404 Not Found\"2025-12-11 05:34:05,775 | INFO | httpx | HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=florentgbelidji/deepseek-ocr-dataset \"HTTP/1.1 200 OK\"2025-12-11 05:34:05,885 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/tree/7c711a21ad466896107bdd1732321a2192b1291b/data?recursive=true&expand=false \"HTTP/1.1 200 OK\"2025-12-11 05:34:06,026 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/tree/7c711a21ad466896107bdd1732321a2192b1291b?recursive=false&expand=false \"HTTP/1.1 200 OK\"2025-12-11 05:34:06,048 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/florentgbelidji/deepseek-ocr-dataset/resolve/7c711a21ad466896107bdd1732321a2192b1291b/dataset_infos.json \"HTTP/1.1 404 Not Found\"2025-12-11 05:34:06,155 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/florentgbelidji/deepseek-ocr-dataset/resolve/7c711a21ad466896107bdd1732321a2192b1291b/data/train-00000-of-00001.parquet \"HTTP/1.1 302 Found\"2025-12-11 05:34:06,221 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/florentgbelidji/deepseek-ocr-dataset/xet-read-token/7c711a21ad466896107bdd1732321a2192b1291b \"HTTP/1.1 200 OK\""
     ]
    }
   ],
   "source": [
    "logs(stage3_done, tail=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
