{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek OCR Job Pipeline\n",
    "\n",
    "This notebook runs a three-stage OCR pipeline on Hugging Face Jobs:\n",
    "\n",
    "1. **Extract** – Run DeepSeek OCR over a dataset, save Markdown and crop detected figures\n",
    "2. **Describe** – Generate captions for extracted figures  \n",
    "3. **Assemble** – Enrich Markdown with figure captions\n",
    "\n",
    "All stages share a single HF dataset repository. Each stage loads the dataset, processes it, and pushes updates back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo, fetch_job_logs, inspect_job, run_uv_job, whoami\n",
    "from huggingface_hub._jobs_api import JobInfo, JobStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "USERNAME = whoami()[\"name\"]\n",
    "\n",
    "HUB_IMAGE = \"vllm/vllm-openai:v0.12.0\"\n",
    "HARDWARE = \"a100-large\"\n",
    "TIMEOUT = \"3h\"\n",
    "\n",
    "CODE_REPO = f\"{USERNAME}/deepseek-ocr-job-code\"\n",
    "DATASET_REPO = f\"{USERNAME}/deepseek-ocr-dataset\"\n",
    "\n",
    "# Source dataset\n",
    "SOURCE_DATASET = \"HuggingFaceM4/FineVision\"\n",
    "SOURCE_CONFIG = \"olmOCR-mix-0225-documents\"\n",
    "MAX_SAMPLES = 10000\n",
    "\n",
    "print(f\"Code: {CODE_REPO} | Dataset: {DATASET_REPO}\")\n",
    "print(f\"Source: {SOURCE_DATASET}/{SOURCE_CONFIG} ({MAX_SAMPLES} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base environment for all stages\n",
    "BASE_ENV = {\n",
    "    # vLLM\n",
    "    \"MODEL_ID\": \"deepseek-ai/DeepSeek-OCR\",\n",
    "    \"SERVED_MODEL_NAME\": \"deepseek-ocr\",\n",
    "    \"HOST\": \"0.0.0.0\",\n",
    "    \"PORT\": \"8000\",\n",
    "    \"MAX_MODEL_LEN\": \"8192\",\n",
    "    \"GPU_MEMORY_UTILIZATION\": \"0.90\",\n",
    "    \"TENSOR_PARALLEL_SIZE\": \"1\",\n",
    "    # Code\n",
    "    \"JOB_CODE_REPO\": CODE_REPO,\n",
    "    \"JOB_CODE_REVISION\": \"main\",\n",
    "    \"JOB_CODE_LOCAL_DIR\": \"/tmp/deepseek-ocr-job-code\",\n",
    "    # Auth\n",
    "    \"HF_TOKEN\": os.environ.get(\"HF_TOKEN\", \"\"),\n",
    "    # Prompts\n",
    "    \"DOC_PROMPT\": \"<image>\\n<|grounding|>Convert this document to Markdown.\",\n",
    "    \"DOC_MAX_TOKENS\": \"4096\",\n",
    "    \"DOC_TEMPERATURE\": \"0.1\",\n",
    "    \"FIGURE_PROMPT\": \"<image>\\nDescribe this image in detail.\",\n",
    "    \"FIGURE_MAX_TOKENS\": \"512\",\n",
    "    \"FIGURE_TEMPERATURE\": \"0.6\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload code to HF Hub\n",
    "CODE_PATHS = [\n",
    "    Path(\"ds-batch-ocr.py\"),\n",
    "    Path(\"hf_job_runner.py\"),\n",
    "    Path(\"ds_batch_ocr\"),\n",
    "]\n",
    "\n",
    "api = HfApi()\n",
    "create_repo(repo_id=CODE_REPO, repo_type=\"dataset\", exist_ok=True)\n",
    "create_repo(repo_id=DATASET_REPO, repo_type=\"dataset\", exist_ok=True)\n",
    "\n",
    "bundle_dir = Path(tempfile.mkdtemp(prefix=\"job-code-\"))\n",
    "for path in CODE_PATHS:\n",
    "    src = Path.cwd() / path if not path.is_absolute() else path\n",
    "    if src.is_dir():\n",
    "        shutil.copytree(src, bundle_dir / path.name, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(src, bundle_dir / path.name)\n",
    "\n",
    "api.upload_folder(folder_path=str(bundle_dir), repo_id=CODE_REPO, repo_type=\"dataset\")\n",
    "print(f\"Uploaded code to {CODE_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "CODE_URL = f\"https://huggingface.co/datasets/{CODE_REPO}/resolve/main/hf_job_runner.py\"\n",
    "\n",
    "def launch(stage: str, flavor: str, env: dict) -> JobInfo:\n",
    "    full_env = {**BASE_ENV, **env, \"PIPELINE_STAGE\": stage}\n",
    "    job = run_uv_job(CODE_URL, image=HUB_IMAGE, flavor=flavor, env=full_env, timeout=TIMEOUT)\n",
    "    print(f\"Launched {stage}: {job.url}\")\n",
    "    return job\n",
    "\n",
    "def wait(job: JobInfo, poll: int = 60) -> JobInfo:\n",
    "    while True:\n",
    "        info = inspect_job(job_id=job.id)\n",
    "        stage = info.status.stage\n",
    "        print(f\"  {job.id}: {stage}\")\n",
    "        if stage not in {JobStage.RUNNING, \"RUNNING\", \"UPDATING\"}:\n",
    "            return info\n",
    "        time.sleep(poll)\n",
    "\n",
    "def logs(job: JobInfo, tail: int = 100):\n",
    "    for line in list(fetch_job_logs(job_id=job.id, namespace=job.owner.name))[-tail:]:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Extract\n",
    "stage1 = launch(\"extract\", flavor=HARDWARE, env={\n",
    "    \"DATASET_NAME\": SOURCE_DATASET,\n",
    "    \"DATASET_CONFIG\": SOURCE_CONFIG,\n",
    "    \"DATASET_SPLIT\": \"train\",\n",
    "    \"MAX_SAMPLES\": str(MAX_SAMPLES),\n",
    "    \"OUTPUT_DIR\": \"./outputs/extract\",\n",
    "    \"EXTRACT_BATCH_SIZE\": \"256\",\n",
    "    \"EXTRACT_MAX_CONCURRENCY\": \"8\",\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_PATH_IN_REPO\": \"outputs/extract\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_done = wait(stage1)\n",
    "print(f\"Extract complete: {DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs(stage1_done, tail=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Describe\n",
    "stage2 = launch(\"describe\", {\n",
    "    \"OUTPUT_DIR\": \"./outputs/describe\",\n",
    "    \"DESCRIBE_BATCH_SIZE\": \"8\",\n",
    "    \"DESCRIBE_MAX_CONCURRENCY\": \"4\",\n",
    "    \"SOURCE_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_done = wait(stage2)\n",
    "print(f\"Describe complete: {DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs(stage2_done, tail=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Assemble\n",
    "stage3 = launch(\"assemble\", {\n",
    "    \"SOURCE_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_REPO_ID\": DATASET_REPO,\n",
    "    \"HF_COMMIT_MESSAGE\": \"Add assembled documents with figure captions\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_done = wait(stage3)\n",
    "print(f\"Pipeline complete! Dataset: https://huggingface.co/datasets/{DATASET_REPO}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs(stage3_done, tail=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
